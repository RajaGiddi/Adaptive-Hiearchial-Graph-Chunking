{"method": "fixed", "num_chunks": 11, "avg_chunk_len": 756.6363636363636, "std_chunk_len": 135.23129864137002, "max_chunk_len": 800, "min_chunk_len": 329, "total_chars": 8323, "compression_ratio": 1.0008410428931875, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4\n\narXiv:2511.03762v1 [eess.IV] 5 Nov 2025\n\n1\n\nSchool of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de\n\nKeywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements\n\n1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models wh", "en treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than", "methods that rely on images as input.\n\n2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.\n\nlost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes pl", "ace on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.\n\n3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space", "measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course", "of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.\n\n4\n\nImplementation and Results\n\nOur training dataset is comprised of 1", "200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.\n\nTitle Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The", "decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.\n\nEach scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of", "two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.\n\n5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY. Zhang", "et al.\n\nTable 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.\n\nAcc.\n\nSyn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.\n\n6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmenta", "tion maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "sliding", "num_chunks": 20, "avg_chunk_len": 795.9, "std_chunk_len": 15.358710883404244, "max_chunk_len": 800, "min_chunk_len": 729, "total_chars": 15918, "compression_ratio": 0.523306948109059, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4\n\narXiv:2511.03762v1 [eess.IV] 5 Nov 2025\n\n1\n\nSchool of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de\n\nKeywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements\n\n1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models wh", "y of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de\n\nKeywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements\n\n1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation", "en treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than", "class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.\n\n2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data", "methods that rely on images as input.\n\n2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.\n\nlost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes pl", "is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.\n\nlost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required", "ace on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.\n\n3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space", "to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.\n\n3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the", "measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course", "nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while t", "of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.\n\n4\n\nImplementation and Results\n\nOur training dataset is comprised of 1", "he SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.\n\n4\n\nImplementation and Results\n\nOur training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.\n\nTitle Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image d", "200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.\n\nTitle Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The", "omain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.\n\nEach scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariat", "decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.\n\nEach scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of", "ions (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the", "two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.\n\n5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY. Zhang", "proposed baselines across all tested accelerations.\n\n5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY. Zhang et al.\n\nTable 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.\n\nAcc.\n\nSyn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.90", "et al.\n\nTable 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.\n\nAcc.\n\nSyn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.\n\n6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmenta", "2 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.\n\n6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "sentence", "num_chunks": 42, "avg_chunk_len": 198.61904761904762, "std_chunk_len": 200.2556642538723, "max_chunk_len": 762, "min_chunk_len": 20, "total_chars": 8342, "compression_ratio": 0.9985614960441141, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4\n\narXiv:2511. 03762v1 [eess. IV] 5 Nov 2025\n\n1\n\nSchool of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.", "zhang@tum. de\n\nKeywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements\n\n1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes.", "Goal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction. Approach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.", "Results: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines. Impact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.", "2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc. ) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes.", "In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.", "lost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image. While segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6].", "Formulating the task as\nan end-to-end learning problem has shown further improvements [2]. We hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.", "3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step. We postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.", "An overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers.", "In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors. The decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities.", "The segmentation output is supervised\non Dice and binary cross-entropy losses. 4\n\nImplementation and Results\n\nOur training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.", "Title Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively.", "The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors.", "The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities. Each scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan.", "Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU. We evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64.", "Our approach is compared to the performance of two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images.", "As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.", "5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY.", "Zhang et al. Table 1: Dice scores and Hausdorff distances over a testing set of 100 subjects. Acc.", "Syn-Net\nLI-Net\nOurs\nDice 0. 749 0. 260 0.", "805 0. 198 0. 902 0.", "089\n4 \nHD 6. 809 2. 776 6.", "557 3. 160 4. 797 2.", "064\nDice 0. 748 0. 258 0.", "809 0. 192 0. 902 0.", "089\n8 \nHD 6. 794 2. 868 7.", "019 3. 521 4. 772 2.", "253\nDice 0. 742 0. 264 0.", "800 0. 197 0. 903 0.", "085\n16 \nHD 6. 792 2. 818 6.", "841 2. 971 4. 509 2.", "068\nDice 0. 723 0. 287 0.", "752 0. 242 0. 902 0.", "086\n32 \nHD 7. 383 3. 122 7.", "531 3. 131 4. 665 2.", "054\nDice 0. 733 0. 261 0.", "799 0. 190 0. 902 0.", "085\n64 \nHD 7. 543 2. 972 6.", "706 2. 567 4. 911 2.", "356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role. 6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step.", "Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "paragraph", "num_chunks": 36, "avg_chunk_len": 229.41666666666666, "std_chunk_len": 336.28843233483695, "max_chunk_len": 1082, "min_chunk_len": 1, "total_chars": 8259, "compression_ratio": 1.0085966824070711, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4", "arXiv:2511.03762v1 [eess.IV] 5 Nov 2025", "1", "School of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de", "Keywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements", "1", "Synopsis", "Motivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.", "2", "Introduction", "In cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail", "2", "Y. Zhang et al.", "lost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.", "3", "Method", "In this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the", "mathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.", "4", "Implementation and Results", "Our training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.", "Title Suppressed Due to Excessive Length", "3", "Fig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.", "Each scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.", "5", "Discussion", "Due to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently", "4", "Y. Zhang et al.", "Table 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.", "Acc.", "Syn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.", "6", "Conclusion", "To the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "recursive", "num_chunks": 44, "avg_chunk_len": 187.52272727272728, "std_chunk_len": 217.632351438296, "max_chunk_len": 751, "min_chunk_len": 1, "total_chars": 8251, "compression_ratio": 1.0095745970185432, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4", "arXiv:2511.03762v1 [eess.IV] 5 Nov 2025", "1", "School of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de", "Keywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements", "1", "Synopsis", "Motivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes. Goal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.", "Approach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities. Results: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.", "Impact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.", "2", "Introduction", "In cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail", "2", "Y. Zhang et al.", "lost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image. While segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6].", "Formulating the task as\nan end-to-end learning problem has shown further improvements [2]. We hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.", "3", "Method", "In this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step. We postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.", "An overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers.", "In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the", "mathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.", "4", "Implementation and Results", "Our training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.", "Title Suppressed Due to Excessive Length", "3", "Fig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.", "Each scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component.", "Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU. We evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines.", "Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab.", "1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.", "5", "Discussion", "Due to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently", "4", "Y. Zhang et al.", "Table 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.", "Acc.", "Syn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.", "6", "Conclusion", "To the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "semantic", "num_chunks": 8, "avg_chunk_len": 1039.375, "std_chunk_len": 631.2693437630248, "max_chunk_len": 2121, "min_chunk_len": 94, "total_chars": 8315, "compression_ratio": 1.0018039687312086, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4\n\narXiv:2511.03762v1 [eess.IV] 5 Nov 2025\n\n1\n\nSchool of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de", "Keywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements", "1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.", "2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.\n\nlost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.", "3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.", "4\n\nImplementation and Results\n\nOur training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.\n\nTitle Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.\n\nEach scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.", "5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY. Zhang et al.\n\nTable 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.\n\nAcc.\n\nSyn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.", "6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "delimiter", "num_chunks": 36, "avg_chunk_len": 229.41666666666666, "std_chunk_len": 336.28843233483695, "max_chunk_len": 1082, "min_chunk_len": 1, "total_chars": 8259, "compression_ratio": 1.0085966824070711, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4", "arXiv:2511.03762v1 [eess.IV] 5 Nov 2025", "1", "School of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de", "Keywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements", "1", "Synopsis", "Motivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.", "2", "Introduction", "In cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail", "2", "Y. Zhang et al.", "lost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.", "3", "Method", "In this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the", "mathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.", "4", "Implementation and Results", "Our training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.", "Title Suppressed Due to Excessive Length", "3", "Fig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.", "Each scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.", "5", "Discussion", "Due to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently", "4", "Y. Zhang et al.", "Table 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.", "Acc.", "Syn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.", "6", "Conclusion", "To the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "token_limit", "num_chunks": 11, "avg_chunk_len": 756.6363636363636, "std_chunk_len": 135.23129864137002, "max_chunk_len": 800, "min_chunk_len": 329, "total_chars": 8323, "compression_ratio": 1.0008410428931875, "avg_chunk_tokens": 188.72727272727272, "max_chunk_tokens": 200, "min_chunk_tokens": 82, "tokenizer": "", "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4\n\narXiv:2511.03762v1 [eess.IV] 5 Nov 2025\n\n1\n\nSchool of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de\n\nKeywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements\n\n1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models wh", "en treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than", "methods that rely on images as input.\n\n2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.\n\nlost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes pl", "ace on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.\n\n3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space", "measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course", "of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.\n\n4\n\nImplementation and Results\n\nOur training dataset is comprised of 1", "200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.\n\nTitle Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The", "decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.\n\nEach scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of", "two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.\n\n5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY. Zhang", "et al.\n\nTable 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.\n\nAcc.\n\nSyn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.\n\n6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmenta", "tion maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "format_aware", "num_chunks": 1, "avg_chunk_len": 8329.0, "std_chunk_len": 0.0, "max_chunk_len": 8329, "min_chunk_len": 8329, "total_chars": 8329, "compression_ratio": 1.0001200624324649, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4\n\narXiv:2511.03762v1 [eess.IV] 5 Nov 2025\n\n1\n\nSchool of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de\n\nKeywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements\n\n1\n\nSynopsis\n\nMotivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes.\nGoal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.\nApproach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities.\nResults: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.\nImpact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.\n\n2\n\nIntroduction\n\nIn cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail\n\n2\n\nY. Zhang et al.\n\nlost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image.\nWhile segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6]. Formulating the task as\nan end-to-end learning problem has shown further improvements [2].\nWe hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.\n\n3\n\nMethod\n\nIn this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step.\nWe postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.\nAn overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers. In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the\n\nmathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.\n\n4\n\nImplementation and Results\n\nOur training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.\n\nTitle Suppressed Due to Excessive Length\n\n3\n\nFig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.\n\nEach scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component. Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU.\nWe evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines. Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab. 1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.\n\n5\n\nDiscussion\n\nDue to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently\n\n4\n\nY. Zhang et al.\n\nTable 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.\n\nAcc.\n\nSyn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.\n\n6\n\nConclusion\n\nTo the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
{"method": "hybrid", "num_chunks": 44, "avg_chunk_len": 187.52272727272728, "std_chunk_len": 217.632351438296, "max_chunk_len": 751, "min_chunk_len": 1, "total_chars": 8251, "compression_ratio": 1.0095745970185432, "chunks": ["Reconstruction-free segmentation from\nundersampled k-space using transformers\nYundi Zhang1,2 , Nil Stolt-Ans 1,3 , Jiazhen Pan1,2 Wenqi Huang1,2 ,\nKerstin Hammernik1,4 , and Daniel Rueckert1,2,3,4", "arXiv:2511.03762v1 [eess.IV] 5 Nov 2025", "1", "School of Computation, Information and Technology, Technical University of\nMunich, Germany\n2\nSchool of Medicine, Klinikum Rechts der Isar, Technical University of Munich,\nGermany\n3\nMunich Center for Machine Learning, Technical University Munich\n4\nDepartment of Computing, Imperial College London, UK\nyundi.zhang@tum.de", "Keywords: Cardiac CINE MRI Unsupervised learning Representation learning K-space mearsurements", "1", "Synopsis", "Motivation: High acceleration factors place a limit on MRI image reconstruction. This limit is extended to segmentation models when treating these as subsequent independent processes. Goal: Our goal is to produce segmentations directly from sparse k-space measurements without the need for intermediate image reconstruction.", "Approach: We employ a transformer architecture to encode global k-space information into latent features. The produced latent vectors condition queried\ncoordinates during decoding to generate segmentation class probabilities. Results: The model is able to produce better segmentations across high acceleration factors than image-based segmentation baselines.", "Impact: Cardiac segmentation directly from undersampled k-space samples circumvents the need for an intermediate image reconstruction step. This allows\nthe potential to assess myocardial structure and function on higher acceleration\nfactors than methods that rely on images as input.", "2", "Introduction", "In cardiac magnetic resonance (CMR) imaging, an abundance of quantitative\nclinical metrics (such as ejection fraction, strain, etc.) are derived from segmentation-based modeling of the myocardium. Image reconstruction and segmentation are typically thought of as independent serial processes. In order to reduce\nacquisition time, k-space data is usually undersampled and reconstruction techniques are employed. These approaches attempt to recover the pixel-level detail", "2", "Y. Zhang et al.", "lost during this process. However, accurate segmentation does not strictly benefit from this level of precision, often relying on high level information about the\noverall content of the image. While segmentation of cardiac images predominantly takes place on clean\nimages [1], previous works have attempted to tackle higher accelerations by performing segmentation directly on unrefined images [6].", "Formulating the task as\nan end-to-end learning problem has shown further improvements [2]. We hypothesize that the process of magnetic resonance (MR) image reconstruction requires larger amounts k-space samples than what theoretically would\nbe required to extract a segmentation signal from the raw data. Under this assumption, direct segmentation from k-space has the potential to allow the quantification of relevant clinical metrics under higher acceleration factors, while\nfurther decreasing acquisition time.", "3", "Method", "In this work, we demonstrate that Transformers [7] are capable of employing\nglobal attention to leverage all available k-space measurements to predict accurate segmentation maps. The architecture is able to perform this task directly\nfrom a set of sampled k-space points, without a need for zero-filling or interpolating the k-space, and without any form of intermediate reconstruction step. We postulate that multi-headed attention, unlike convolutional approaches, offers the necessary properties to appropriately process the nature of k-space: (1)\nthe mechanism considers global correlations, (2) feature extraction should be\ninsensitive to the relative order in which the same samples are presented, (3)\ninputs of arbitrary sparsity are supported.", "An overview of the architecture is presented in Fig. 1. Our architecture s encoder extracts features from the sparse input k-space samples into a latent space\nover the course of 4 layers.", "In order to efficiently handle hundreds of thousands\nof k-space samples\nwhile avoiding the", "mathcalO N 2 memory complexity of naive self-attention in standard transformers, our encoder utilizes alternating cross-attention (CA) and self-attention\n(SA) blocks as proposed by Perceiver [3]. The CA blocks project global k-space\ninformation into a fixed bottleneck of latent vectors, while the SA blocks contextualize features between latent vectors.\nThe decoder consists of 4 cross-attention blocks, which use the extracted\nlatent information to condition any queried image-domain coordinate into producing segmentation class probabilities. The segmentation output is supervised\non Dice and binary cross-entropy losses.", "4", "Implementation and Results", "Our training dataset is comprised of 1200 mid-ventricular slices of cardiac shortaxis scans from the UK-Biobank dataset [4]. The dataset is divided into training,\nvalidation, and testing sets containing 1000, 100, and 100 samples, respectively.", "Title Suppressed Due to Excessive Length", "3", "Fig. 1: Overview of DiSK architecture. N , M , and P represent the number of\nsampled points in k-space, latent vectors, and query points in image domain,\nrespectively. The encoder is made up of L Perceiver layers [3] which alternates cross-attention and latent self-attention blocks. Specifically, cross-attention\nblocks project global features of the set of input k-space samples K into a fixeddimensional latent bottleneck of M vectors. Self-attention between latent vectors\ncontextualizes the extracted global features between the vectors. The decoder is\nmade up of L cross-attention layers which condition queried image-domain coordinates with the encoder s latent vectors into segmentation class probabilities.", "Each scan has 50 frames with an average in-plane resolution of approximately\n80x80 pixels per frame. We create synthetic undersampled k-space data onthe-fly for each 2D+time scan. Each frame, we apply additional Gaussian B0\nvariations (in order to remove the conjugate symmetry of k-space) and generate\nCartesian undersampling masks by sampling normally distributed lines centered\non the DC component.", "Implementation and training was performed using the\nPytorch library on an NVIDIA A40 GPU. We evaluate the performance of models trained on acceleration factors 4, 8,\n16, 32, and 64. Our approach is compared to the performance of two imagebased segmentation baselines.", "Following [6], we implement a model based on the\nU-Net [5] architecture (Syn-Net) and an autoencoder approach (LI-Net). Their\nwork showed these models to be capable of producing segmentations on noisy\nreconstructions of undersampled images. As shown in Tab.", "1 and Fig. 2, our\nmodel obtains higher segmentation Dice scores and lower Hausdorff distances\nthan the proposed baselines across all tested accelerations.", "5", "Discussion", "Due to the nature of short-axis acquisitions, the heart is consistently on the\nsame general location and orientation across the dataset. It is therefore easy for\nthe models to achieve a decent performance at high accelerations by memorizing\na general shape and location. Despite this, our model appears to consistently", "4", "Y. Zhang et al.", "Table 1: Dice scores and Hausdorff distances over a testing set of 100 subjects.", "Acc.", "Syn-Net\nLI-Net\nOurs\nDice 0.749 0.260 0.805 0.198 0.902 0.089\n4 \nHD 6.809 2.776 6.557 3.160 4.797 2.064\nDice 0.748 0.258 0.809 0.192 0.902 0.089\n8 \nHD 6.794 2.868 7.019 3.521 4.772 2.253\nDice 0.742 0.264 0.800 0.197 0.903 0.085\n16 \nHD 6.792 2.818 6.841 2.971 4.509 2.068\nDice 0.723 0.287 0.752 0.242 0.902 0.086\n32 \nHD 7.383 3.122 7.531 3.131 4.665 2.054\nDice 0.733 0.261 0.799 0.190 0.902 0.085\n64 \nHD 7.543 2.972 6.706 2.567 4.911 2.356\nproduce better approximations of the true anatomy. We suspect that our model s\nability to attend globally across all time frames plays a key role.", "6", "Conclusion", "To the best of our knowledge, this is the first study that explores the prediction\nof cardiac segmentation maps directly from sparse under-sampled k-space measurements without an explicit image reconstruction step. Our results show that\ntransformer architectures are capable of extracting global features from sparse\nk-space measurements and improve segmentation performance over image-based\nbaselines at high acceleration factors."]}
