Asymptotics of constrained
M -estimation under convexity

arXiv:2511.04612v1 [math.ST] 6 Nov 2025

Victor-Emmanuel Brunel 

Abstract: M -estimation, aka empirical risk minimization, is at the
heart of statistics and machine learning: Classification, regression, location estimation, etc. Asymptotic theory is well understood when the
loss satisfies some smoothness assumptions and its derivatives are dominated locally. However, these conditions are typically technical and can
be too restrictive or heavy to check. Here, we consider the case of a convex loss function, which may not even be differentiable: We establish an
asymptotic theory for M -estimation with convex loss (which needs not
be differentiable) under convex constraints. We show that the asymptotic distributions of the corresponding M -estimators depend on an
interplay between the loss function and the boundary structure of the
set of constraints. We extend our results to U -estimators, building on
the asymptotic theory of U -statistics. Applications of our work include,
among other, robust location/scatter estimation, estimation of deepest
points relative to depth functions such as Oja s depth, etc.
Key words and phrases: Constrained M -estimation, empirical risk minimization, convex loss, convex analysis, consistency, asymptotic distribution, U -statistics, metric projections, directional derivatives..
1. INTRODUCTION
1.1 Preliminaries
We consider a sequence X1 , X2 , . . . of independent, identically distributed (iid) random variables
taking values in some measurable space (E, E) and we denote by P their distribution. Let Θ0 Rd
be a non-empty set, which can be interpreted as a parameter space. Here, d 1 is a fixed integer
representing the parameter dimension.
Let ϕ E Θ0 R be a function such that ϕ( , θ) is measurable and in L1 (P ), for all θ Θ0 .
Set Φ(θ) = E[ϕ(X1 , θ)], for all θ Θ0 . The goal of M -estimation (or empirical risk minimization) is
to estimate a minimizer of Φ when only finitely many samples from P are available. For n 1 and
1 n
θ Θ0 , let Φn (θ) = ϕ(Xi , θ). For θ Θ, Φ(θ) is called the population risk evaluated at θ, while
n i=1
Φn (θ) is the empirical risk based on X1 , . . . , Xn . The idea of M -estimation is to use the random
function Φn as a surrogate for Φ and estimate a minimizer of Φ by selecting a minimizer of Φn .
When minimization is performed over the whole parameter space Θ0 , we talk about unconstrained
M -estimation, or simply M -estimation. If we minimize Φn on a closed subset Θ of Θ0 , we talk
about constrained M -estimation with Θ as the set of constraints. In this work, we are concerned
with the latter.

CREST-ENSAE, victor.emmanuel.brunel@ensae.fr

1

2

V.-E. BRUNEL

Let Θ Θ be the set of minimizers of Φ on Θ and assume it is not empty. For all n 1, let θ n be a
minimizer of Φn (provided it exists and can be chosen in a measurable way - see Section 2.2 below).
Standard asymptotic theory questions (weak or strong) consistency and aims at determining the
asymptotic distribution of a rescaled version of the M -estimator. That is, does d(θ n , Θ ) converge
(in probability or almost surely) to zero as n ? Here, d(θ n , Θ ) is simply the distance of θ n

to the non-empty set Θ . If Θ reduces to a singleton Θ = {θ }, does ρn (θ n θ ) converge in
distribution for some rescaling factor ρn and if so, what is the asymptotic distribution?
n 

It may be convenient to consider, instead of θ n , a near minimizer of Φn , that is, a random variable
θ n satisfying Φn (θ n ) inf θ Θ Φn (θ) + εn where εn is a (possibly random) small enough error term.
For simplicity, here, we only study the properties of exact empirical risk minimizers.
Our main working assumption is that the loss function is convex in its second argument. That
is, Θ0 and Θ are convex sets and ϕ(x, ) is convex on Θ0 for P -almost all x E. Relevant examples
include:
1. Location estimation: E = Θ0 = Rd , ϕ(x, θ) = (x θ) for some convex function Rd R.
For instance, if is the squared Euclidean norm, we recover mean estimation. If is the
Euclidean norm, we recover geometric median estimation. If (x) = x (1 2α)u x, where
α (0, 1) and u Rd with u = 1 are fixed ( being the Euclidean norm), we recover
geometric quantile estimation (e.g., if d = 1 and u = 1, Θ is simply the set of α-quantiles
of P ). Huber s M -estimators, adding robustness to mean estimators, correspond to the loss
 (x) = hc ( x ), x Rd , where for all t 0, hc (t) = t2 if t c, hc (t) = 2ct c2 if t > c and c > 0
is a given, tuning parameter.
2. Location estimation on matrix spaces: Let E = Θ0 = Sd+ be the space of d d symmetric,
positive semi-definite matrices. There are several ways of averaging positive definite matrices,
beyond simply taking their arithmetic mean (i.e., their standard linear average). A simple
example is that of the harmonic mean, which is simply the inverse of the linear average of
the inverses (if the matrices are positive definite). More involved ways include (again for
positive definite matrices) the Karsher mean, which, in the case of 2 such matrices, reduces to
their geometric mean [7]. In the context of optimal transport, a large body of literature has
been interested in the Bures-Wasserstein mean of positive definite matrices, which is related
to Wasserstein barycenters on the set of Gaussian distributions [2, 54]. In fact, it is shown
in [30, Lemma A.5] that the Bures-Wasserstein mean is the solution to a convex optimization
problem. Hence, as it is done in [30], the Bures-Wasserstein barycenter of iid, random, positive
(semi-)definite matrices can be analyzed under the prism of M -estimation with convex loss,
and our results also allows to consider the constrained case, as well as robust alternatives to
Bures-Wasserstein barycenters (such as the Bures-Wasserstein median, see [2]).
3. Linear regression (here, data are rather denoted as pairs (Xn , Yn ) Rd R, n 1): E = Rd R,
Θ = Rd , ϕ((x, y), θ) = (y θ x) for some R R (which, again in our context, we assume
to be convex). If (t) = t2 , we recover least squares estimation. If (t) = t , this is median
regression, etc.
In all these examples, we can take Θ0 = Θ = Rd (or Sd+ ), corresponding to unconstrained estimation, but we could also assume that Θ is a closed, strict subset of Θ0 . Perhaps the simplest
example is the case when E = Θ0 = Rd , Θ Rd is a compact convex subset and ϕ(x, θ) = x θ 2 . In
that case, it is easy to check that θ = πΘ (E[X]) and θ n = πΘ (X n ) are the unique minimizers of Φ
and Φn respectively, where X n = n 1 ni=1 Xi and πΘ is the metric projection on Θ. Of course, this
example can be studied with elementary tools, but it is worth keeping it in mind as an illustration
of our results, in order to fix ideas.

ASYMPTOTICS OF CONVEX M -ESTIMATION

3

Typically, proving consistency and finding the asymptotic distribution of M -estimators require
some tools from the theory of empirical processes and imposes some smoothness of the loss function
ϕ in its second argument. Moreover, it is often assumed that the partial derivatives of ϕ, with respect
to its second argument, are locally dominated, allowing the use of dominated convergence to swap
derivatives and expectations in the analysis. In our context, the full power of convexity comes in
through fairly elementary convex analysis and allows to completely avoid such common technical
assumptions.
1.2 Related works
M -estimation is a quintessential problem in statistical inference (maximum likelihood estimation
being a particular instance in general) and, as a particular case, constrained M -estimation.
Asymptotic theory of statistical estimation has been overlooked in the era of high-dimensional
data and models. Yet, it provides benchmarks for non-asymptotic theory and asymptotic approximations produce less conservative inference than non-asymptotic approaches, and they are relevant
when the data set contains a lot of samples and their dimension is not too large.
Asymptotic theory of M -estimators is well understood when the loss function is smooth and
satisfies local domination properties [31,55,56]. Under similar smoothness and domination assumptions, [18] also derived asymptotic properties in the constrained case, when the set of constraints is
a regular closed set and the population minimizer is a local minimum of the population risk in the
ambient space. See also [34] for inference on constrained statistical problems and [26,47] for special
cases. Recently, [35] drew connections between the statistical error of constrained M -estimation
and the statistical dimension of the constrained set, building on [11, 46] in linear regression and
Gaussian sequence models. Even though these connections belong to the non-asymptotic world, we
also discuss such connections at infinitesimal scales in the remarks following Theorem 7 below.
When the loss function is convex, [19] proved asymptotic normality, only requiring the population
risk (that is, Φ) being twice differentiable at the (unique) population minimizer, with positive
definite Hessian at that point - convexity allowing to avoid any local domination assumption. [40]
proved further asymptotic expansions of the statistical error under stronger smoothness assumptions
of convex the loss.
Asymptotics of penalized M -estimators have also been established [24], in particular for penalized
regression (such as Lasso) [27].
In the context of high dimensional linear regression and classification, some recent work has also
tackled the asymptotics of penalized M -estimators and bagged penalized M estimators in growing
dimension (that is, when the dimension d also diverges with the sample size) [5, 6, 29]. Related to
this line of work are the high-dimensional central limit theorems of [12, 15] which correspond to
the squared Euclidean loss in the context of M -estimation. To the best of our knowledge, similar
high-dimensional central limit theorems have not been tackled for general M -estimators.
This work is not concerned with penalized M -estimation. Indeed, even though penalized and
constrained optimization problems are related through Lagrangian functions, in penalized statistical
problems, it is standard to let the penalty depend on the sample size in order to enforce some
regularization and achieve optimal performance, although here, we only consider fixed constraint
sets, independently of the sample size.
1.3 Outline
In Section 2, we give some key lemmas that we use in our main results. Section 2.1 gathers some
results about convex functions and sequences of convex functions, which we chose to highlight
in the first part of this work because they are essential to build the intuition behind the theory.
In Section 2.2, which is much more theoretical and could be skipped at first, we deal with the

4

V.-E. BRUNEL

existence of a measurable empirical minimizer, based on results that guarantee the existence of
measurable selections. Section 3 focuses on consistency of convex M -estimators and Section 4 deals
with asymptotic distributions of M -estimators. We propose an extension to U -estimators with
convex loss in Section 5. More lemmas about convex functions, convex sets and cones, and metric
projections, which are only used for some technical parts of the main proofs, but not essential to
build the intuition, are deferred to the appendix. However, Section C, in the appendix, on directional
differentiability of metric projections onto convex sets, may be of independent interest to the reader.
1.4 Notation and standard definitions/assumptions
Here, we gather all the notation that we use in this work, as well as several simple definitions.
1. In this work, ( , F, P) is a fixed probability space and we assume that all the random variables
that we consider are defined on that space. We let X1 , X2 , . . . be iid random variables with
values in a measurable space E and we let P = X1 #P be their distribution. The set Θ0 is a
fixed, open, convex subset of Rd and Θ is a closed, convex subset of Θ0 . The loss function
ϕ E Θ0 R is assumed to be measurable in its first argument and convex in its second,
and to satisfy ϕ( , θ) L1 (P ) for all θ Θ0 . We let Φ(θ) = E[ϕ(X1 , θ)] for all θ Θ0 (referred
to as population risk ) and for all n 1, ω and θ Θ0 , Φn (ω, θ) = n 1 ni=1 ϕ(Xi (ω), θ)
(referred to as empirical risk ). For simplicity, unless this amount of precision is needed, we
simply write Φn (θ) and skip the dependence on ω .
2. The power set of a non-empty set A is denoted by P(A).
3. Given a subset G Rd , we denote by int(G) its interior, cl(G) its closure and G = cl(G) 
int(G) its boundary.
4. Any symmetric, positive definite matrix S Rd d yields a scalar product by setting, for
1/2
x, y Rd , x, y S = x Sy. The associated Euclidean norm is given by x S = x, x S for all
x Rd . The corresponding Euclidean ball with center x Rd and radius r 0 is denoted by
BS (x, r).
5. Given a vector u Rd , the linear subspace of Rd that is orthogonal to u with respect to , S
is denoted by u S : If u = 0, u S = Rd and if u 0, u S is some linear hyperplane. When L Rd ,
we denote by L S the linear subspace of Rd that is orthogonal to L with respect to , S .
S
= {x C 
6. For a set C Rd , a vector u Rd and a real number t R, we denote by Cu,t
S
S
 u, x S = t}, which may be empty. When t = 0, we simply write Cu = Cu,t .
7. The distance of a point x Rd to a closed set C Rd with respect to the Euclidean norm
associated with S is denoted by dS (x, C) = miny C x y S .
8. The metric projection onto a non-empty, closed convex set C Rd with respect to , S is
S
S
: For all u Rd , πC
(u) is the unique minimizer of the map t C t u 2S . In
denoted by πC
S
particular, dS (u, C) = u πC
(u) S .
d
9. Let G R be a non-empty, closed, convex set and x0 G. The tangent cone to G at x0 is
the set of all t Rd such that x0 + εt G for all small enough ε > 0. It is a convex cone,
not necessarily closed. Its closure is called the support cone to G at x0 . Let S Rd d be
symmetric, positive definite. The normal cone to G at x0 with respect to S is the set of all
t Rd satisfying t, x x0 S 0 for all x G. It is a closed, convex cone. When there is no
mention of a matrix S, it is implicitly assumed to be the identity matrix.
10. The support function of a non-empty convex set C Rd is the map hC Rd R { }
defined by hC (t) = supu C u t. If t 0, it is the largest (signed) distance from the origin to a
hyperplane orthogonal to t and that is tangent to C. It is easy to check that hC is a sublinear
function (that is, positively homogeneous and convex). If C is bounded, then hC only takes
finite values. See, e.g., [49, Section 1.7.1].

ASYMPTOTICS OF CONVEX M -ESTIMATION

5

11. In all notation above, when S is the identity matrix, we drop the subscript or superscipt S
and simply write, for instance, x , B(x, r), u , Cu , πC , etc.
12. Given a set C Rd and a function f C R, the set of minimizers (resp. maximizers) of f
on C is denoted by Argminy C f (y) (resp. Argmaxy C f (y)). This set may be empty. When
this set is a singleton, we denote by argminy C f (y) (resp. argmaxy C f (y)), with lower case
 a , the unique element of that set.
13. Let f be a function defined on a subset of Rd , with values in Rp for some p 1 (for us,
in practice, p = 1 or d). Then, given a point x in the interior of the domain of f , we say
that f has a directional derivative at x in the direction t Rd if and only if the quantity
ε 1 (f (x + εt) f (x)) has a limit as ε 0, with ε > 0. In that case, we denote this limit by
d+ f (x; t). Note that if f has directional derivatives at x Rd , then it must be continuous
at x. Moreover, the map d+ f (x; ) is automatically measurable, since the limit can be taken
along the sequence ε = 1/k, k 1. If the ratio ε 1 (f (x + εt) f (x)) converges uniformly in t on
all compact subsets of Rd , we say that f has directional derivatives at x in Hadamard sense.
This is equivalent to requiring that for all t Rd , for all sequences (tn )n 1 converging to t and
for all seuqences (εn )n 1 of positive numbers converging to 0, ε 1
n (f (x + εn tn ) f (x)) has a
(finite) limit as n (see, e.g., [17, Chapter III]).
14. If f is differentiable at x, we denote by df (x; ) its differential. That is, df (x; t) = d+ f (x, t) =
 f (x) t for all t Rd .
15. Given a convex set G0 Rd , when we talk about a convex function on G0 , we always mean
that it takes finite values only, i.e., we only consider convex functions f G0 R, which may
be the restriction to G of some lower-semicontinuous convex function f Rd R { } whose
domain contains G0 .
16. We call random convex function any map f G R, where G Rd is some convex set,
such that f ( , t) is measurable for all t G and f (ω, ) is convex for all ω . We could only
assume that f (ω, ) is convex for P-almost all ω , but this does not bring significantly more
generality. Unless we need to emphasize the dependence on ω explicitly, we rather write f (t)
instead of f (ω, t) for simplicity.
17. The covariance matrix of a random vector X in Rd with two moments is defined as var(X) =
E[XX ] E[X]E[X] = E[(X E[X])(X E[X]) ]. That is, for all vectors u, v Rd ,
u var(X)v = cov(u X, v X). When S Rd d is symmetric, positive definite, we denote
by varS (X) = Svar(X)S = var(SX) so that for all vectors u, v Rd , we have the identity
u varS (X)v = cov( u, X S , v, X S ). This is the matrix representation of the covariance operator of X corresponding to the Euclidean structure defined by S.
18. For all vectors u Rd and symmetric, positive semi-definite matrices V Rd d , we denote by
Nd (u, V ) the d-variate Gaussian distribution with mean u and covariance matrix V .
2. KEY LEMMAS ABOUT DETERMINISTIC AND RANDOM CONVEX FUNCTIONS
2.1 On the behavior of convex functions and sequences of convex functions
First, we state a minimum principle for convex functions, which we will use a few times in the
next sections.
Lemma 1. Let G0 Rd be an open convex set and G G0 be a closed convex subset. Let
f G0 R be a convex function and K G0 be any compact, convex set. If mint K G f (t) > f (t0 )
for some t0 K G, then Argmin f (t) K and it is not empty.
t G

Remark 1.

 Recall that a convex function defined on an open convex set is automatically

6

V.-E. BRUNEL

continuous on that set [48, Theorem 10.1], hence, it automatically reaches its bounds on any
compact set.
 The phrasing of this lemma is a bit technical, but a simpler version, when G = G0 = Rd , says
that if f has one value inside K that is smaller than all values taken on K, then, it has at
least one minimizer, and they all lie in K. We need this slightly more technical statement in
order to deal with constrained M -estimation later.
Proof. Fix some arbitrary t G K and let us show that necessarily, f (t) > f (t0 ). Set ϕ λ 
[0, 1] f (t0 + λ(t t0 )), which is a convex function. First, note that t0 K (or else, t0 would be in
 K G so f (t0 ) min K G f , which would contradict the assumption). Hence, there must be some
λ (0, 1) such that t0 + λ (t t0 ) K. Moreover, since both t0 and t are in G, t0 + λ (t t0 ) G.
Therefore, by assumption, ϕ(λ ) > ϕ(0). Hence, convexity of ϕ implies that it must be increasing
on [λ , 1], yielding that ϕ(1) ϕ(λ ) and hence, that ϕ(1) > ϕ(0). That is, f (t) > f (t0 ).
Therefore, the minimizers (if any) of f on G must be contained in K. Finally, there must be at
least one such minimizer since f is continuous on the compact set K G.
In the main statistical results presented in the next sections, Lemma 1 will be used to localize
empirical minimizers of Φn .
The second key result is due to Rockafellar and shows that, for sequences of convex functions,
uniform convergence can be deduced from pointwise convergence on a dense subset. From this
lemma, we will derive two probabilistic corollaries.
Lemma 2. [48, Theorem 10.8] Let G0 Rd be an open convex set and f, f1 , f2 , . . . be convex
functions on G0 . Assume that there is a dense subset C of G0 such that for all t C, fn (t) f (t).
Then, fn converges uniformly to f on all compact subsets of G0 .
An important consequence that we will use extensively is the following corollary.
Corollary 1. Let f, f1 , f2 , . . . be random convex functions defined on an open convex set
G0 Rd . Assume that fn (t) f (t) almost surely (resp. in probability) for all t G0 . Then, for
n 

all compact sets K G0 , supK fn f 0 almost surely (resp. in probability).
n 

Proof. Let us prove the statement for the almost sure convergence and the convergence in
probability separately.
Almost sure convergence.
Let C be a dense and countable subset of G0 . By assumption, for each t C, it holds with
probability one that fn (t) f (t). Since C is countable, this implies that with probability 1,
n 

fn (t) f (t) for all t C simultaneously. Hence, by Lemma 2, with probability 1, fn converges
n 
uniformly to f on all compact subsets of G0 .
Convergence in probability.
Again, let C be a dense and countable subset of G0 and fix a compact subset K of G0 . Our
goal is to show that Zn = supt K fn (t) f (t) 0 in probability. It is necessary and sufficient
n 

to show that every subsequence of (Zn )n 1 has a further subsequence that converges to 0 almost
surely [13, Section 3.3, Lemma 2]. With no loss of generality (since we could just renumber the
terms of the sequence), let us prove that (Zn )n 1 has a subsequence that converges to 0 almost
surely. Denote by t1 , t2 , . . . the elements of C.

ASYMPTOTICS OF CONVEX M -ESTIMATION

7

By assumption, fn (t1 ) f (t1 ) in probability, so it has a subsequence that converges almost
n 

surely. That is, there is an increasing map ψ1 N N such that fψ1 (n) (t1 ) f (t1 ) almost
n 
surely.
Similarly, (fψ1 (n) (t2 ))n 1 being a subsequence of (fn (t2 ))n 1 , it converges almost surely to f (t2 )
and thus has a further subsequence (fψ1 (ψ2 (n)) (t2 ))n 1 that converges almost surely to f (t2 ). By
induction, one can construct a sequence of increasing maps ψp N N , p 1, such that for all
integers p 1, fψ1 ... ψp (n) (tp ) converges to f (tp ) almost surely. Let ψ(n) = ψ1 . . . ψn (n), for all
n 1. This is an increasing map; Let us prove that Zψ(n) 0 almost surely, which will prove
n 
the lemma.
First, note that with probablity 1, fψ1 ... ψp (n) (tp ) converges to f (tp ) simultaneously for all p 1.
Second, for all p 1, (fψ(n) (tp ))n 1 is a subsequence of (fψ1 ... ψp (n) (tp ))n 1 (except maybe for the
first p terms of the sequence). Hence, fψ(n) (tp ) f (tp ) for all p 1, almost surely. The rest
n 

follows from the first part of the proof (the case of almost sure convergence).
In fact, we can also derive a similar corollary for Lp convergence, for any p 1. We defer it to
the appendix (Section E), because we only use it to formulate an open question, see the end of
Section 4.2).
2.2 On the existence of measurable minimizers and measurable subgradients
The existence of minimizers of a random convex function can often be established quite easily
(for instance, if the function is coercive). Same for subgradients since any convex function defined
on an open convex set has at least one subgradient at any point of that set. However, the existence
of a measurable minimizer or subgradient is much less trivial and relies on the theory of measurable
selections.
2.2.1 Measurable selections
Definition 1. Let Γ P(Rd ) be a multifunction, that is, a function that maps any ω 
to some non-empty set Γ(ω) Rd . A measurable selection of Γ is a measurable map γ Rd
such that for all ω , γ(ω) Γ(ω).
There are numerous theorems that guarantee the existence of measurable selections in various
setups, see [21,38]. The one that we will need is the following, that follows from combining Theorems
3.2 (ii), 3.5 and 5.1 of [21]. Denote by C the collection of all non-empty, closed subsets of Rd .
Lemma 3. Let Γ C be a multifunction. Assume that for all compact sets K Rd , the
set {ω Γ(ω) K } is measurable (that is, it belongs to the σ-algebra F ). Then, Γ has a
measurable selection.
A multifunction satisfying this property above is called C-measurable (C as in compact , the
test sets K used in Lemma 3 being compact).
2.2.2 Measurable empirical risk minimizers
From Lemma 3, we obtain the following result, which will guarantee the existence of a measurable
empirical risk minimizer for large enough n, and which will, at the same time, yield its strong
consistency.
Theorem 1. Let f, f1 , f2 , . . . be random convex functions defined on an open convex set G0 Rd
such that for all t G0 , fn (t) f (t) almost surely. Let G G0 be a closed, convex set. Assume
n 

8

V.-E. BRUNEL

that G = Argmint G f (t) is non-empty and compact. Then, there exists a sequence (tn )n 1 of
random variables with values in G such that with probability 1, tn is a minimizer of fn on G for
all large enough n. Moreover, d(tn , G ) 0 almost surely.
n 

Proof. For n 1, let Mn = Argmint G fn (t), possibly empty. We proceed in two steps. First,
we prove that with probability 1, Mn is non-empty for all large enough n. Second, we use the
measurable selection to obtain such a sequence (tn )n 1 .
Step 1. Note that if G is compact, then Mn for all n 1, since fn is convex, hence continuous,
on the open set G0 .
First, Corollary 1 yields that fn converges uniformly to f on any compact subset of G0 , almost
surely. Fix some arbitrary, small enough ε > 0 such that G ε = {t Rd d(t, G ) ε}. This set is
compact, so
(1)

sup fn (t) f (t) 0.
n 

t G ε G

Let f = mint G f (t) be the smallest value of f on G (note that f is measurable, since it can
be written as the infimum of f (t) for t ranging in a countable, dense subset of G). Convexity of f
on the open set G0 implies its continuity. Therefore, η = mint G ε G f (t) f > 0.
Then, the following holds with probability 1: For all sufficiently large integers n and for all
t G ε G,
fn (t) f (t) η/3

 f + η η/3

by (1)
by definition of η

 fn (t ) η/3 + η η/3

again by (1)

= fn (t ) + η/3 > fn (t ).
Therefore, by Lemma 1, it holds with probability 1 that, for all large enough integers n 1,
(2)

 Mn G ε .

 Mn if Mn 
Step 2. Now, fix an arbitrary element t0 G. For all integers n 1, let Γn = 

 {t0 } otherwise.
Let us prove that Γn has a measurable selection, for all n 1. Since Mn is always closed (by
continuity of fn ), Γn is always non-empty and closed, so by Lemma 3, it is sufficient to check that
for each n 1, the multiset function Γn C is C-measurable in order to guarantee the existence
of a measurable selection.
Fix n 1 and let K Rd be any compact set and let us show that the set {ω Γn (ω) K }
is a measurable set.
First, rewrite {ω Γn (ω) K } = {ω Mn (ω) K } {ω Mn (ω) = , t0 K}.
Since fn (ω, )1 is continuous for every ω , the first set in this union can be rewritten as {ω 
inf t G fn (ω, t) = inf t K G fn (ω, t)}. Again, using continuity of fn (ω, ) for all ω , we can rewrite
inf t G fn (ω, t) and inf t K G fn (ω, t) as inf t G 1 fn (ω, t) and inf t G 2 fn (ω, t) respectively, where G1
and G2 are dense, countable subsets of G and K G respectively. Therefore, both inf t G fn (ω, t)
and inf t K G fn (ω, t) are measurable (as maps from to R { }) and we obtain that {ω 
Mn (ω) K } F.
1

recall that above, we only wrote fn (t) instead of fn (ω, t) for simplicity.

9

ASYMPTOTICS OF CONVEX M -ESTIMATION

Now, {ω Mn (ω) = , t0 K} is empty if t0 K, which is measurable. If t0 K, it reduces to
the set {ω Mn (ω) = }, which can be decomposed as
{ω Mn (ω) = } = 

 {ω 

p N q p+1

min
t G B(t0 ,q)

fn (ω, t) <

min
t G B(t0 ,q)

fn (ω, t)}

which, therefore, is also measurable.
Finally, Lemma 3 implies the existence of a sequence (tn )n 1 of random variables such that for
all n 1, tn Γn . Furthermore, by Step 1 of this proof, we also obtain that with probability 1,
tn Mn for all large enough n.
Step 3. Finally, following the reasoning of Step 1, (2) yields that for all ε > 0, it holds, with
probability 1, that d(tn , G ) ε for all large enough n. That is, d(tn , G ) 0 almost surely.
n 

2.2.3 Measurable subgradients
Now, we apply Lemma 3 to show the existence of measurable subgradients for random convex
functions. Recall that for a convex function f defined on a convex set G0 Rd , a subgradient of f
at a point t0 G0 is any vector u Rd such that
f (t) f (t0 ) + u (t t0 ),

 t G0 .

We denote by f (t0 ) the collection of all subgradients of f at t0 . If t0 int(G0 ), then f (t0 ) is nonempty, compact and convex by Lemma 5. In particular, if G0 is open, then f has subgradients at
every point of G0 . Now, if f is a random convex function, the existence of a measurable subgradient
(i.e., that is chosen in a measurable way) at t0 int(G0 ) is granted by the following theorem.
Theorem 2. Let f be a random convex function defined on a convex set G0 Rd and let
t0 int(G0 ). Then, f has a measurable subgradient at t0 .
Proof. Let Γ = f (t0 ) be the set of subgradients of f at t0 (that is, for all ω , Γ(ω) =
 (f (ω, )) (t0 )). Since t0 int(G0 ), Γ only takes non-empty values. Moreover, by Lemma 5, it
always takes closed values, so Γ is a C-valued multifunction. Hence, it is sufficient to check that it
is C-measurable in order to apply Lemma 3.
Let K Rd be any arbitrary compact set. Lemma 4 yields that Γ K if and only if there
exists u K with the property that supt B(t0 ,ε) (u (t t0 ) f (t) + f (t0 )) 0 where ε > 0 is any
small enough positive number satisfying that B(t0 , ε) int(G0 ). Since f is convex, it is continuous
on int(G) and, hence, on B(t0 , ε). Let C be a fixed dense, countable subset of B(t0 , ε). Then,
Γ K if and only if there exists u K for which supt C (u (t t0 ) f (t) + f (t0 )) 0. Let
h(ω, u) = supt C (u (t t0 ) f (ω, t) + f (ω, t0 )), for all ω and u Rd (again, here, we emphasize
the dependence on ω for clarity, even though it was omitted above). First, note that for all
u Rd , h( , u) is measurable, as the supremum of a countable family of measurable functions.
Second, for all ω , the function h(ω, ) is convex as the supremum of affine functions, and it
only takes finite values: Indeed, C B(t0 , ε) is bounded and f (ω, ) is continuous on B(t0 , ε).
Hence, h(ω, ) is continuous on Rd . Therefore, since K is compact, Γ(ω) K if and only if
minu K h(ω, u) 0, if and only if inf u K h(ω, u) 0, where K is a fixed, countable, dense subset of
K. Therefore, we obtain {ω Γ(ω) K } = {ω inf h(ω, u) 0} which is measurable,
u K 

since inf u K h( , u) is a measurable map.

10

V.-E. BRUNEL

Finally, let us state an incredibly simple yet powerful result that shows that for convex functions,
there is no need to apply any dominated convergence theorem in order to swap expectations and
(sub-) gradients. It is very easy to check that if f1 and f2 are two convex functions on a convex set
G0 Rd , then for all t0 G0 , f1 (t0 ) + f2 (t0 ) (f1 + f2 )(t0 )2 . The following lemma shows that
this fact still holds for generalized sums of convex functions.
Theorem 3. Let f be a random convex function defined on a convex set G0 Rd . For all
t int(G0 ), let g(t) be a measurable subgradient of f at t. Let p 1 be a real number and assume
that for all t G0 , f (t) Lp (P) and denote by F (t) = E[f (t)]. Then, F is a convex function and
for all t G0 , g(t) Lp (P) and
E[g(t)] F (t).
Proof. Fix t0 int(G0 ) and let g(t0 ) be a measurable subgradient of h at t0 (the existence of
which is guaranteed by Theorem 3). In order to check that g(t0 ) Lp (P), it is necessary and sufficient
to check that each of its d coordinates are in Lp (P) or, equivalently, that for all v Rd , g(t0 ) v p is
integrable. Fix an arbitrary v Rd and let ε > 0 be such that t0 + εv and t0 εv are in G0 (such an
ε exists because t0 int(G0 )). Then, by definition of subgradients, g(t0 ) v ε 1 (f (t0 + εv) f (t0 ))
and g(t0 ) v ε 1 (f (t0 εv) f (t0 )). That is,
 g(t0 ) v max(ε 1 (f (t0 + εv) f (t0 )), ε 1 (f (t0 εv) f (t0 ))).
Since the right hand side is in Lp (P) by assumption, so is g(t0 ) v. The vector v was arbitrary, so
we conclude that g(t0 ) Lp (P).
Now, for the rest of the proof, simply note that, again, by definition of subgradients,
f (t) f (t0 ) + g(t0 ) (t t0 )
holds for all t G0 . Taking the expectation, which is linear, yields that
F (t) F (t0 ) + E[g(t0 )] (t t0 )
which concludes the proof.

Remark 2.
 In fact, to obtain that g(t0 ) Lp (P), it would have been sufficient to assume that f (t) Lp (P)
for all t B(t0 , ε), for any arbitrary, small enough ε > 0.
 As a consequence of Theorem 3, if F is differentiable at t0 int(G0 ), then E[g(t0 )] does not
depend on the choice of the measurable selection g(t0 ) and it is automatically equal to F (t0 )
(since F (t0 ) is the only subgradient of F at t0 , in that case).
 In fact, Lemma 12 shows that if F is differentiable at some t0 int(G0 ), then f is almost surely
differentiable at t0 , so in that case, any measurable selection g(t0 ) must satisfy g(t0 ) = f (t0 )
almost surely.
 To the best of our knowledge, the converse inclusion to Theorem 3 is unknown: Can all
subgradients of F at t0 be written as E[g(t0 )] for some measurable g(t0 ) f (t0 )?
2

The other inclusion is also true if G0 has non-empty interior but, perhaps surprisingly, requires a nontrivial
argument.

ASYMPTOTICS OF CONVEX M -ESTIMATION

11

3. CONSISTENCY
Consistency of empirical risk minimizers with a convex loss function is automatically granted in
a strong sense, thanks to Lemma 1 which allows to localize the M -estimator, for large enough n, in
an arbitrarily small neighborhood of the set of population minimizers with probability 1. In what
follows, we consider a sequence (θ n )n 1 of random variables such that with probability 1, for all
large enough n, θ n is a minimizer of Φn on Θ. Existence of such a sequence is granted by Theorem 1.
Theorem 4. Assume that Θ is compact and non-empty. Then, d(θ n , Θ ) 0 almost
n 
surely, as n .
The proof of this theorem can be found in [19] (the only difference here being that we do not
assume that Θ = Rd ), and it is a direct consequence of Theorem 1 above.
Remark 3. Theorem 4 shows that any empirical minimizer becomes, with probability 1, arbitrarily close to the set of population minimizers Θ . A converse statement is generally not true,
that is, there can be elements of Θ that may never be approached by any empirical minimizer. For
instance, let E = Rd , Θ = B(0, 1) and ϕ(x, θ) = x θ. Furthermore, assume that X1 has the standard
normal distribution. Then, Φ(θ) = E[X] θ = 0 for all θ Θ, so Θ = Θ. However, Φn (θ) = X n θ, so
with probability 1, the empirical minimizer is unique, given by θ n = X n / X n .
4. ASYMPTOTIC DISTRIBUTION
In this section, we assume that Argminθ Θ Φ(θ) is a singleton and we denote by θ = argminθ Θ Φ(θ).
4.1 Non-differentiable case
We first study asymptotic properties of θ n without assuming differentiability of Φ at θ . That
is, Φ(θ ) may not be not a singleton.
The following useful property is fundamental in that case. Recall that for a non-empty convex
subset C Rd , we denote by hC Rd R { } its support function.
Proposition 1. Assume that ϕ( , θ) L2 (P ) for all θ Θ0 . Let (ρn )n 1 be any non-decreasing
sequence of positive numbers diverging to as n . Then, for all θ Θ0 and t Rd ,
ρn (Φn (θ + t/ρn ) Φn (θ)) h Φ(θ) (t)
n 

in probability.
Proof. Fix θ Θ0 . For all t Rd , define
1 n
t g(Xi , θ))
nρn i=1
1
 ρn (Φ(θ + t/ρn ) Φ(θ) t E[g(X1 , θ)]) .
ρn

Fn (t) = ρn (Φn (θ + t/ρn ) Φn (θ) 

Write Fn (t) = ni=1 (Zi,n E[Zi,n ]) where Zi,n = ρnn (ϕ(Xi , θ + t/ρn ) ϕ(Xi , θ) (1/ρn )t g(Xi , θ)),
for all i = 1, . . . , n. Convexity of ϕ(Xi , ) yields that 0 Zi,n n1 t (g(Xi , θ + t/ρn ) g(Xi , θ)), for
all i = 1, . . . , n. By Theorem 3, each Zi,n , i = 1, . . . , n, is square-integrable. Hence, taking the square
and the expectation in the last display,
2
E[Zi,n
] 

1
E[Yn2 ]
n2

12

V.-E. BRUNEL

where Yn = t (g(X1 , θ + t/ρn ) g(X1 , θ)). Since (ρn )n 1 is non-decreasing, Lemma 11 implies that
2
the sequence (Yn )n 1 is non-increasing, yielding that E[Zi,n
] n12 E[Y12 ] and, by independence of
X1 , X2 , . . .,
n
n
n
E[Y12 ]
2
var ( Zi,n ) = var(Zi,n ) E[Zi,n
] 
 0.
n 
n
i=1
i=1
i=1
We conclude that Fn (t) 0 in L2 and, hence, in probability. Now, rewrite Fn (t) as
n 

Fn (t) = ρn (Φn (θ + t/ρn ) Φn (θ))
(3)

1 n
 t ( g(Xi , θ) E[g(X1 , θ)])
n i=1

(4)

 ρn (Φ(θ + t/ρn ) Φ(θ)) .

The law of large numbers yields that the term (3) converges to 0 in probability, and the term in
(4) goes to d+ Φ(θ; t) as n . The result then follows from Lemma 9.
As a consequence, we obtain the following theorem.
Theorem 5. Assume that ϕ( , θ) L2 (P ) for all θ Θ0 and that 0 int( Φ(θ )). Then, θ n = θ 
with probability going to 1 as n .
Note that the assumption that 0 int( Φ(θ )) readily implies that θ must be the unique
minimizer of ϕ on Θ and even on Θ0 . It also implies that Φ is not differentiable at θ .
Proof. Let (ρn )n 1 be any non-decreasing sequence of positive numbers diverging to as
n . Since Θ0 is open, we can find r > 0 such that B(θ , r) Θ0 . For all n 1, denote by
Tn = {t Rd θ + t/ρn Θ} = ρn (Θ θ ). Finally, set Gn (t) = ρn (Φn (θ + t/ρn ) Φn (θ )), for all
t Rd such that θ + t/ρn Θ0 . By definition of θ n , t n = ρn (θ n θ ) is a minimizer of Gn on Tn for
all large enough n, with probability 1.
Now, fix ε > 0. Combining Proposition 1, Corollary 1 and Lemma 9, we get
sup Gn (t) h Φ(θ ) (t) 0
n 

t B(0,ε)

in probability (note that B(0, ε) ρn (Θ0 θ ) for all large enough integers n). Now, since 0 
int( Φ(θ )), the quantity η = minu Rd u =1 h Φ(θ ) (u) is positive.
Assume that n is large enough so supt B(0,ε) Gn (t) h Φ(θ ) (t) εη/2 with probability at least
1 ε. When this inequality is satisfied, we get that, for all t Tn with t = ε,
Gn (t) h Φ(θ ) (t) εη/2
= εh Φ(θ ) (t/ε) εη/2
 εη εη/2

by positive homogeneity of h Φ(θ )

by definition of η

> εη/2
> 0 = Gn (0)
yielding, thanks to Lemma 1, that t n cannot be larger than ε. Hence, we have shown that
for all large enough n, it holds with probability at least 1 ε that ρn (θ n θ ) ε. That is,
ρn (θ n θ ) 0 in probability. Since this must hold for any positive, non-decreasing sequence
n 

(ρn )n 1 diverging to as n , Lemma 25 implies the desired statement.

ASYMPTOTICS OF CONVEX M -ESTIMATION

13

Let C be the support cone to Θ at θ . Recall that the first order condition (Lemma 10) yields
that C h 1
 Φ(θ ) ([0, )). The next result extends Theorem 5.
Theorem 6. Assume that ϕ( , θ) L2 (P ) for all θ Θ0 and that h Φ(θ ) (t) > 0 for all t C {0}.
Then, with probability going to 1 as n , θ n = θ .
The assumption of the theorem is that the two closed, convex cones C and {t Rd h Φ(θ ) (t) 0}
have a trivial intersection. Note that, by the first order condition at θ , this intersection must always
be included in the boundary of C. In other words, the assumption of the theorem is that all (nonzero) vectors in C are directions of strict, linear increase of the population risk Φ.
Proof. A consequence of the assumption of the theorem is that for all ε > 0, {t C h Φ(θ ) (t) 
ε} is compact. Indeed, it is closed, since C is closed and h Φ(θ ) is continuous. Moreover, the set {t 
C t = 1} is compact, so by continuity of h Φ(θ ) , there is some t0 C with t0 = 1 satisfying, for all
t C {0}, h Φ(θ ) (t) t h Φ(θ ) (t0 ). The assumption of the theorem implies that h Φ(θ ) (t0 ) > 0.
Finally, {t C h Φ(θ ) (t) ε} is bounded, since it is included in B(0, ε/h Φ(θ ) (t0 )).
Now, let (ρn )n 1 be an arbitrary non-decreasing sequence of positive numbers, diverging to as
n and fix ε > 0. Proposition 1, Corollary 1 and Lemma 9, yield that supt C h Φ(θ ) (t) ε Gn (t) 
h Φ(θ ) (t) 0 in probability, where we set Gn (t) = ρn (Φn (θ + t/ρn ) Φn (θ )) as in the proof
n 

of Theorem 5. Let n be large enough so supt C h Φ(θ ) (t) ε Gn (t) h Φ(θ ) (t) ε/2 with probability
at least 1 ε. Then, with probability at least 1 ε, it holds simultaneously for all t Tn = ρn (Θ θ )
with h Φ(θ ) (t) = ε, that
Gn (t) h Φ(θ ) (t) ε/2 = ε/2 > 0 = Gn (0)
so, by Lemma 1, any minimizer t n of Gn on Tn satisfies h Φ(θ ) (t n ) ε. In particular, we obtain,
for all large enough n, that with probability at least 1 ε,
0 h Φ(θ ) (ρn (θ n θ )) = ρn h Φ(θ ) (θ n θ ) ε
where the first inequality follows from the first order condition for Φ at θ (Lemma 10). That
is ρn h Φ(θ ) (θ n θ ) 0. Since the sequence (ρn )n 1 was arbitrary, Lemma 25 yields that
n 

h Φ(θ ) (θ n θ ) = 0 with probability going to 1 as n . Since θ n θ C, this means that
θ n θ = 0 with probability going to 1 as n , which is the desired statement.
Remark 4. Results of this section rely on Proposition 1, which imposes square-integrability of
the loss function. We do not know whether the same results could be proved under weaker assumptions.
Now, to obtain a more precise asymptotic description of θ n when Φ is differentiable at θ (this
could be the case in Theorem 6, with Φ(θ ) t > 0 for all t C {0}, but not in Theorem 5), we
will assume the existence of second order derivatives for Φ at θ . This is the object of the next
section.
4.2 Differentiable case
Let us first state the main result of this section.
Theorem 7.
following:

Let g E Θ0 Rd be a measurable selection of subgradients of ϕ. Assume the

14

V.-E. BRUNEL

(i) Φ is twice differentiable at θ and S = 2 Φ(θ ) is positive definite;
(ii) g( , θ ) L2 (P );
S
 1
(iii) πΘ θ
 Φ(θ ).
 has directional derivatives at S
Then,

S
 1
n(θ n θ ) d+ πΘ θ
 Φ(θ ); Z)
 ( S
n 

 1

 1

in distribution, where Z Nd (0, S BS ) and B = var(g(X1 , θ )).
Remark 5 (on the assumptions of the theorem).
(i) Second differentiability of Φ at θ is not a strong restriction, since all convex functions are
twice differentiable almost eveywhere in the interior of their domains [1]. The assumption
that 2 Φ(θ ) is definite positive is made in order to obtain n 1/2 convergence rate. This
assumption could be relaxed, yielding slower rates under further, technical assumptions on
higher order derivatives on Φ. In this work, we choose to focus on the n 1/2 rate because it
only requires minimal, easy to check, non-restrictive smoothness assumptions.
(ii) Existence of the map g is guaranteed by Theorem 3. Moreover, the first assumption on Φ
implies that it is differentiable at θ , so by Lemma 12, ϕ(X1 , ) is almost surely differentiable
at θ yielding that g(x, θ ) = (ϕ(x, )) (θ ) for P -almost all x E. Theorem 3 also ensures
that it is sufficient that ϕ( , θ) L2 (P ) for all θ Θ0 for the second assumption to hold. In
fact, a straightforward adaptation of Theorem 3 shows that it is even enough to only assume
that ϕ( , θ) L2 (P ) for all θ in any arbitrarily small neighborhood of θ . Note that this does
not require a uniform domination of ϕ or its derivatives/subgradients in any neighborhood of
θ but, rather, a pointwise integrability condition of order 0 (that is, on ϕ itself ).
S
S
(iii-a) Directional differentiability of πΘ θ
 is not a strong restriction in the sense that, πΘ θ being non-expansive (see Lemma 13) it is automatically differentiable almost everywhere by
Rademacher s theorem [16, Section 3.1.6, p. 216]. In the appendix (Section C), we present
S
for a
several sufficient conditions that guarantee the existence of directional derivatives of πK
convex set K, at a direction u, which, in practice, are easily checked (e.g., u K, or u K and
 K is smooth at πK (u), or K is defined by finitely many linear convex constraints, etc.). By
an obvious linear change of variables, it is clear that the existence of a directional derivative
S
 1
of πΘ θ
 Φ(θ ) in a direction z Rd is equivalent to the existence of a directional
 at S
derivative of πS 1/2 (Θ θ ) at S 1/2 Φ(θ ) in the direction S 1/2 z. Then, simple algebra yields
that
S
 1
d+ πΘ θ
 Φ(θ ); z) = S 1/2 d+ πS 1/2 (Θ θ ) ( S 1/2 Φ(θ ); S 1/2 z).
 ( S
Recall that (θ θ ) Φ(θ ) 0 for all θ Θ: This is granted by the first order condition
at θ (Lemma 10). That is, Φ(θ ) is in the normal cone to Θ at θ or, equivalently,
 S 1/2 Φ(θ ) is in the normal cone to S 1/2 (Θ θ ) at 0.
Remark 6 (on the conclusion of the theorem).
 1
S
 Lemma 20 yields that for any z Rd , d+ πΘ θ
 Φ(θ ); z) CSS 1 Φ(θ ) = C Φ(θ ) where
 ( S
C is the support cone to Θ at θ . When Φ(θ ) t > 0 for all t C {0} (that is, Φ(θ ) is
S
 1
in the interior of the normal cone to Θ at θ ), C Φ(θ ) = {0}, d+ πΘ θ
 Φ(θ ); ) = 0 so
 ( S

Theorem 7 yields that n(θ n θ ) 0 in distribution: This was already a (rather weak)
n 
consequence of Theorem 6.
 If θ int(Θ), then the first order condition (Lemma 10) yields that Φ(θ ) = 0 and,

S
d+ πΘ θ
n(θ n θ ) Z
 (0; ) is simply the identity map. Therefore, Theorem 7 says that
n 

ASYMPTOTICS OF CONVEX M -ESTIMATION

15

in distribution. In that case, Theorem 4 implies that, with probability 1, for all large enough
n, θ n int(Θ). Hence, with probability 1, for all large enough n, θ n (the constrained M estimator) is also a solution to the unconstrained optimization problem minθ Θ0 Φn (θ), and
we recover Haberman s theorem [19, Theorem 6.1].
 In fact, Theorem 7 also encompasses the unconstrained case, by taking Θ = Θ0 = Rd . If Θ0
is a strict open subset of Rd , one can also consider an unconstrained M -estimator θ n on the
open set Θ0 , that is, a minimizer of Φn on Θ0 . Assume that θ is the unique minimizer of Φ
on the open set Θ0 and let Θ be any closed subset of Θ0 containing θ in its interior (e.g.,
take Θ = B(θ , ε) for any small enough ε). Then, a straight adaptation of Theorem 4 yields
that θ n θ almost surely, so θ n Θ for all large enough n, with probability 1. That is, θ n
n 
eventually coincides with a constrained M -estimator and, hence, also satisfies the conclusion
S
d
of Theorem 7, with d+ πΘ θ
 (0; ) being the identity map (note that in the case Θ = Θ0 = R ,
we necessarily have that Φ(θ ) = 0).
 If the boundary of Θ is C 2 in a neighborhood of θ (that is, it can be locally represented
as the graph of a C 2 mapping from Rd 1 to R) and Φ(θ ) 0, then, Lemma 15 yields that

n(θ n θ ) converges in distribution to a Gaussian distribution that is supported in the linear
hyperplane that is parallel to the (unique) supporting hyperplane to Θ at θ .
 Lemmas 23 and 24 imply that for all t, t 0 with t > t,
(5)

 1
 1
S
S
 Φ(θ ); Z) S
 Φ(θ ); Z) S d+ πΘ θ
 d+ πΘ θ
 ( tS
 ( t S

almost surely. This can be interpreted as follows. First, note that the set Θ can represent
some constraints that are imposed by a specific application, or it can represent a model (e.g.,
if it is believed that the global minimizer of Φ lies in Θ). In the latter case, the model is
misspecified if the global minimizer of Φ is not in Θ, that is, if Φ(θ ) 0. In other words,
the vector Φ(θ ) (or its rescaled version S 1 Φ(θ ) can be used to quantify the amount
of model misspecification. In that regard, (5) suggests that more misspecification yields better
asymptotic error (we do not account for any misspecification bias here). In (5), t = 0 can be
thought of as corresponding to the well-specified case. This will be illustrated in the examples
below.
 As a consequence of Theorem 7, the mean squared error of θ n satisfies
(6)

 1
S
 Φ(θ ); Z) 2S ]
lim inf nE[ θ n θ 2S ] E[ d+ πΘ θ
 ( S
n 

(we do not know, in general, whether this is in fact an equality, with the lim inf being a
simple limit, see the open question below). The right hand side can be interpreted as a local
measure of the statistical complexity of Θ around θ , relative to the (population) loss function
Φ. The statistical dimension (or Gaussian width) of a non-empty, closed, convex set G Rd
is measured as E[ πG (Z) 2 ] where Z Nd (0, Id ), see [3] (in our case, we need to account
for a scaling given by S 1 and B in the covariance matrix of Z). In (6), we do not have a
projection, but the directional derivative of a projection. The right hand side of (6) can rather
be seen as a statistical dimension at an infinitesimal scale. We can refer, for instance, to [11]
who studied least squares under convex constraint, and proved that the statistical dimension
at a fixed scale drives the statistical error. A similar phenomenon has also been studied for
constrained M -estimators in a more general setup [35]. Recall, however, that except in specific
S
 1
cases (see Section C in the appendix), d+ πΘ θ
 Φ(θ ); ) is not the projection onto a
 ( S
convex set.
S
 1
 It is worth mentioning some further important properties of Π = d+ πΘ θ
 Φ(θ ); ).
 ( S
As we have noted above, in general, it is not the projection onto a convex cone. Nevertheless,

16

V.-E. BRUNEL

it shares similar properties as the projection onto a convex cone. Indeed, by Lemma 21, it
satisfies the following properties:
 Π(λz) = λΠ(z), for all λ 0 and z Rd (positive homogeneity);
 Π(z ) Π(z) S z z 2S (non-expansiveness);
 Π(z ) Π(z), z z S Π(z ) Π(z) 2S 0 for all z, z Rd (firm monotonicity).
Note that non-expansiveness is implied by firm monotonicity. Such maps satisfying the last
two properties above have been studied extensively [57]. Moreover, [43, Proposition 2.1] implies
that Π is the gradient of a convex function.
Now, let us look at some applications of Theorem 7.
Example 1 (Constrained mean estimation). Let X1 , X2 , . . . be iid random vectors with two
moments3 and Θ Rd be a non-empty, closed, convex set. Consider the loss function ϕ(x, θ) =
(1/2) x θ 2 , x, θ Rd . Then, θ = πΘ (E[X1 ]) is the unique minimizer of Φ on Θ and θ n = πΘ (X n )
where X n = n 1 (X1 + . . . + Xn ), for all n 1. Consistency, which is a consequence of Theorem 4,
also follows directly from the strong law of large numbers, together with continuity of πΘ (since it
is non-expansive). For asymptotic normality, we obtain, from Theorem 7, that

n(θ n θ ) d+ πΘ θ (E[X1 ] θ ; Z) = d+ πΘ (E[X1 ]; Z)
n 

in distribution, where Z Nd (0, var(X1 )) (in this example, S = Id ). In this simple case, this result
can also be obtained using the central limit theorem, combined with the delta method4 .
Here, it is clear that misspecification is favorable for the asymptotic error: For instance, if Θ θ 
is a convex cone and E[X1 ] θ is in the interior of the normal cone to Θ at θ (in particular,
θ E[X1 ]), then, Theorem 5 yields that θ n = θ with probability going to 1 as n .
Example 2 (Constrained least squares). Let (X1 , Y1 ), (X2 , Y2 ), . . . be iid random pairs in Rd R.
Assume that X1 has four moments, E[X1 ] = 0, S = E[X1 X1 ] is definite positive, Y1 X1 θ0 is
independent of X1 and has the centered Gaussian distribution with variance σ 2 > 0 for some θ0 Rd
and σ 2 > 0. Let ϕ(x, y, θ) = 1/2(y x θ)2 , for all x Rd , y R and θ Rd . Then, for all θ Rd ,
1
Φ(θ) = θ θ0 2S + σ 2 .
2
Let Θ Rd be a non-empty, closed, convex subset of Rd (here, Θ0 = Rd ). Then, Argminθ Θ Φ(θ) =
S
{πΘ
(θ0 )} and, provided that πΘ has directional derivatives at θ0 , the least square estimator θ n ,
defined as any minimizer on Θ of Φn (θ) = n 1 ni=1 (Yi Xi θ)2 , θ Rd , satisfies

S

+ S
n(θ n θ ) d+ πΘ θ
 (θ0 θ ; Z) = d πΘ (θ0 ; Z)
n 

in distribution, where Z Nd (0, S 1 BS 1 ) and
B = var((Y1 X1 θ )X1 )

= var((Y1 X1 θ0 )X1 + X1 (θ θ0 )X1 )
= E[(X1 (θ0 θ ))2 X1 X1 ] + σ 2 S.

3

In fact, one moment is enough if one rather uses the loss function ϕ(x, θ) = x θ 2 x 2 , x, θ Rd
Delta method requires Hadamard directional differentiability of πΘ θ at E[X1 ] θ . This is readily implied by
the existence of directional derivatives together with non-expansiveness of πΘ θ 
4

17

ASYMPTOTICS OF CONVEX M -ESTIMATION

Example 3 (Geometric median). Let X1 , X2 , . . . be iid random vectors with one moment5 .
Consider the loss function ϕ(x, θ) = x θ , x, θ Rd . Then, θ is any geometric median and θ n is
any empirical geometric median. Here, in the unconstrained case, we recover standard results for
geometric median M -estimation, provided that the distribution of X1 is not supported on an affine
line (this guarantees uniqueness of θ ) and that 1/ X1 θ is integrable (this guarantees that Φ is
twice differentiable at θ with positive definite Hessian), see, e.g., [28].
Proof of Theorem 7. Recall that we denote by S = 2 Φ(θ ), which is a symmetric, positive
definite matrix, by assumption.
First, since Θ0 is open, there exists some r > 0 such that BS (θ , r) Θ0 . Fix some R > 0, whose

value will be determined later, and let n 1 be any integer that is large enough so R/ n r. For
all such integers n, let Fn be the random function defined on B(0, R) by

t n
1
Fn (t) = n(Φn (θ + t/ n) Φn (θ )) ( g(Xi , θ ) + t 2 Φ(θ )t)
2
n i=1
for all t BS (0, R). This is a random convex function. Our first goal is to prove that Fn converges
pointwise (and hence, by Corollary 1, uniformly on the compact set BS (0, R)) to zero in probability.
From this, we will then obtain that any minimizer of the first term (one of which is given by

n(θ n θ ) for large enough n, with probability 1) is close to the unique minimizer of the second,
quadratic term.
Fix t BS (0, R) and n 1. For i = 1, . . . , n, let Zi,n = ϕ(Xi , θ +n 1/2 t) ϕ(Xi , θ ) n 1/2 t g(Xi , θ ).
By definition of subgradients,
0 Zi,n n 1/2 t (g(Xi , θ + n 1/2 t) g(Xi , θ )).
Squaring and taking the expectation yields that
2

2
] n 1 E [(t (g(X1 , θ + n 1/2 t) g(X1 , θ ))) ]
E[Zi,n

(7)

(we replaced i with 1 in the right hand side because the Xi s are iid). Let Yn = t (g(X1 , θ +

n 1/2 t) g(X
1 , θ )). As mentioned above, Yn 0. Moreover, for n 1, letting u = θ + t/ n and

v = θ + t/ n + 1,
Yn Yn+1 = t (g(X1 , u) g(X1 , v))

= (1/ n 1/ n + 1) 1 (u v) (g(X1 , u) g(X1 , v))
 0
by Lemma 11. So the sequence (Yn )n 1 is non-increasing. Hence, Yn converges almost surely to
some non-negative random variable Y . By monotone convergence (noting that Y1 is integrable),
this implies that
E[Yn ] E[Y ].

(8)

n 

However, for all n 1, E[Yn ] = t (wn Φ(θ )) where wn Φ(θ + t/ n), by Lemma 6. Lemma 7
yielding that wn w, we obtain that E[Yn ] 0. Together with (8), this shows that E[Y ] = 0
n 

5

n 

Similarly to the first example, one need not assume the existence of one moment if the loss function is replaced
with ϕ(x, θ) = x θ x , x, θ Rd .

18

V.-E. BRUNEL

and, hence, because Y 0, that Y = 0 almost surely. Therefore, again by monotone convergence
(noting, this time, that Y12 is iontegrable), E[Yn2 ] E[Y 2 ] = 0.
n 

Combined with (7) and using independence of Z1,n , . . . , Zn,n , we obtain that
(9)

n

n

n

i=1

i=1

i=1

2
var ( Zi,n ) = var(Zi,n ) E[Zi,n
] E[Yn2 ] 0.
n 

Therefore, by Chebychev s inequality, ni=1 (Zi,n E[Zi,n ]) 0 in probability, that is,
n 

n

n(Φn (θ +n 1/2 t) Φn (θ )) n 1/2 t g(Xi , θ ) n(Φ(θ +n 1/2 t) Φ(θ ) n 1/2 t Φ(θ )) 0
n 

i=1

in probability. Now, since we have assumed that Φ is twice differentiable at θ , we finally obtain
that
Fn (t) 0

(10)

n 

in probability, for all t BS (0, R), as desired.
For all integers n 1, let Tn = {t Rd θ + n 1/2 t Θ} = n1/2 (Θ θ ) T and Sn = {t Rd 
θ + n 1/2 t Θ0 } = n1/2 (Θ0 θ ). Then, Tn is a closed subset of Sn . Moreover, since θ Θ0 and
Θ0 is open, BS (0, R) Sn for all large enough integers n (recall that R > 0 is some fixed number,
whose value is still to be determined). Define the maps
G n t Sn n(Φn (θ + n 1/2 t) Φn (θ ))
and

n
1
Gn t Rd n 1/2 t g(Xi , θ ) + t 2 Φ(θ )t.
2
i=1

As per these definitions, Fn = G n Gn , so, (10) and Corollary 1 yield that
(11)

sup
t BS (0,R)

 G n (t) Gn (t) 0
n 

in probability.
Moreover, t n = n1/2 (θ n θ ) is a minimizer of G n on Tn , by definition of the empirical risk
minimizer θ n .
Now, denote by Zn = n 1/2 S 1 ni=1 g(Xi , θ ) Φ(θ ) and for all t Rd , rewrite Gn (t) as
n
1
Gn (t) = n 1/2 t g(Xi , θ ) + t 2 Φ(θ )t
2
i=1
n
1
= n 1/2 S 1 g(Xi , θ ), t S + t 2S
2
i=1

1
= Zn + nS 1 Φ(θ ), t S + t 2S
2
 1

1
 2
= t + Zn + nS Φ(θ ) S Zn + nS 1 Φ(θ ) 2S .
2

It is now clear that Gn has a unique minimizer on Tn , which we denote by t n and which is given
by

t n = πTSn ( Zn 

 1
nS Φ(θ )).

19

ASYMPTOTICS OF CONVEX M -ESTIMATION

Now, our goal is twofold. First, to study the asymptotic behavior of t n and show that it converges
in distribution, as n . Second, to check, based on (11), that t n approaches t n as n , that is,
t n t n converges in probability to 0. Using Slutsky s theorem, these two facts will imply convergence
in distribution of t n .
Asymptotic behavior of t n .
First, by the central limit theorem, we have that Zn Z in distribution, where Z is is a
n 

centered Gaussian random variable with covariance matrix given by S 1 var(g(X1 , θ ))S 1 .
By Skorohod representation theorem (see [25, Theorem 5.31] for instance), one may assume
S
that Zn converges almost surely to Z. Since πC
is non-expansive by Lemma 13, it holds that

S
 1

tn πTn ( Z nS Φ(θ )) converges to 0 almost surely. Moreover,

 1
S

πTSn ( Z nS 1 Φ(θ )) = π 
n(Θ θ ) ( Z nS Φ(θ ))
 S
 1/2
= nπΘ θ
Z S 1 Φ(θ ))
 ( n
S
 1
 d+ πΘ θ
 Φ(θ ); Z)
 ( S
n 

almost surely, using the third assumption of the theorem. Therefore, we conclude that t n 
n 

 1
S
 Φ(θ ); Z) almost surely and, hence, in distribution. The desired results follows,
d+ πΘ θ
 ( S
since Z and Z are identically distributed.
Convergence in probability of t n t n to 0.
Fix ε > 0. Since the sequence (t n )n 1 converges in distribution (see the previous paragraph), it
is tight, that is, there must exist some M > 0 such that for all n 1, P ( t n S M ) 1 ε. Let
K = BS (0, M + ε) and fix some η > 0 to be chosen below. (11) yields that for all large enough n 1,
supt K G n (t) Gn (t) η with probability at least 1 ε. Therefore, by the union bound, for all
large enough n 1, it holds with probability at least 1 2ε that simultaneously for all t Tn with
 t t n S = ε,

G n (t) Gn (t) η
ε2
 η
2
ε2
 G n (t n ) η +
 η.
2

 Gn (t n ) +

Hence, chosing η = ε2 /8, we obtain that for all large enough integers n, with probability at least
1 2ε, G n (t) > G n (t n ) simultaneously for all t Tn with t t n S = ε. Corollary 1 yields that for all
large enough integers n, with probability at least 1 2ε, t n t n S ε. That is, t n t n converges in
probability to 0.
S
 1
Conclusion. We have proved that t n converges in distribution to d+ πΘ θ
 Φ(θ ); Z) for
 ( S

some Gaussian random variable Z and that t n tn converges to zero in probability, as n .
Hence, Slutsky s theorem implies the desired result.
In the proof of Theorem 7, the convergence that we obtained in (10) actually holds in the L2
sense (see (9)). Therefore, Corollary 2 implies uniform convergence on all compact subsets in the L2
sense. Yet, it is not clear, from there, how to proceed and prove that t n t n 0 in L2 . Proving
n 

this convergence would yield an exact asymptotic quantification of the mean squared error of θ n ,
since, it would yield that
S
 1
nE[ θ n θ 2 ] E[ d+ πΘ θ
 Φ(θ ); Z) 2 ]
 ( S
n 

20

V.-E. BRUNEL

where Z is a Gaussian vector as in the theorem. We leave the following question open:
Open question. Is it true that under the assumptions of Theorem 7, for all large enough n,
θ n has two moments, and that
S
 1
nE[ θ n θ 2 ] E[ d+ πΘ θ
 Φ(θ ); Z) 2 ]?
 ( S
n 

5. EXTENSION: CONVEX U -ESTIMATION
The previous theory can be easily extended to more general convex empirical risks, e.g., when
Φn (θ) is a U -statistic. With the same notation as in the previous sections, fix some positive integer
k and let ϕ E k Θ0 R be symmetric and measurable in its first k arguments and convex in its
last. Also assume that for all θ Θ0 , ϕ( , θ) L1 (P k ), that is, ϕ(X1 , . . . , Xk , θ) is integrable. Set
Φ(θ) = E[ϕ(X1 , . . . , Xk , θ)] and, for all n k,
Φn (θ) =

1
ϕ(Xi1 , . . . , Xik , θ).

(nk) 1 i1 <...<ik n

Estimators obtained by minimizing such empirical risks are called U -estimators. Some relevant
examples include:
1. Location estimators through depth functions: Let E = Θ0 = Θ = Rd , k = d and ϕ(x1 , . . . , xd , θ)
be the volume of the d-dimensional simplex spanned by x1 , . . . , xd , θ, for all x1 , . . . , xd , θ Rd .
The minimizers of Φ are then called Oja s population medians [44]. Note that ϕ(x1 , . . . , xd , θ)
is the absolute value of an affine function of θ, hence, it is convex in θ. We recover consistency
and asymptotic normality of Oja s empirical medians (see [45]) as particular cases of our
asymptotic theorems (see below for U -estimators). More generally, we refer to [58] for other
definitions of medians that are U -estimators associated with depth functions.
2. Let E = R and Θ Θ0 = R and k 1. [37] proposes a version of the median of mean estimator
defined as a U -estimator obtained by computing an empirical median of all empirical averages
k
of the form k1 i I Xi , for I {1, . . . , n} of size k. That is, ϕ(x1 , . . . , xk , θ) = x1 +...+x
 θ , for
k
all x1 , . . . , xk , θ R. The difference with standard median of mean estimators [32,33,39] is that
in [37], all possible subsamples of size k, with overlaps, are considered. Other frameworks,
such as geometric medians of means in multivariate settings [36] can be considered as well.
Note that in [37], the order k of the U -process is allowed to grow with the sample size n - we
do not consider this setup here and leave it for future work.
3. More generally, aggregation of estimators that are based on overlapping subsamples, e.g.,
random forests [9] or bagging [8], which have attracted lots of interest in modern machine
learning.
4. Scatter estimation and robustness: Let E = R, Θ0 = R, k = 2 and ϕ(x1 , x2 , θ) = ( x1 x2 p θ)
where p 1 and = R R is a convex function. When p = 2 and (u) = u2 , u R, θ n is simply
twice the empirical variance of X1 , . . . , Xn and if = hc for some c > 0 (recall the definition of
hc from Section 1.1), we obtain a robust version of the empirical variance. If now p = 1 and
 (u) = u2 , u R, we obtain Gini s mean absolute difference, while if = , we obtain a proxy
to a median absolute deviation (and intermediate robust versions if = hc for some c > 0).
In higher dimensions, one recovers the empirical covariance matrix of X1 , . . . , Xn by setting
2
ϕ(x1 , x2 , θ) = tr(((x1 x2 )(x1 x2 ) θ)2 ), for all θ Rd d Rd and x1 , x2 Rd . Robust
versions can be defined by taking the square root of the above, or applying Huber s loss hc
for some c > 0.

ASYMPTOTICS OF CONVEX M -ESTIMATION

21

5. Empirical risk minimization where the choice of loss function itself depends on the data (e.g.,
for data driven procedures), see, e.g., [53].
Note that U -statistics depending on a parameter (here, Φn (θ), θ Θ0 ) have been studied as
U -processes, see, e.g., [4, 41, 42]. Here, we first recall the classical law of large numbers and central
limit theorem for U -statistics.
Theorem 8. Law of large numbers for U -statistics [20, Theorem 8.6] Let h E k Rd be a
symmetric, measurable map satisfying h L1 (P k ). Then,
1
h(Xi1 , . . . , Xik ) E[h(X1 , . . . , Xk )]

n 
(nk) 1 i1 < <ik n
almost surely.
Theorem 9. Central limit theorem for multivariate U -statistics [22, Theorem 7.1], [20, Theorem 8.9] Let h E k Rd be a symmetric, measurable map satisfying h L2 (P k ). Let Σ be the
1
covariance matrix of E[h(X1 , . . . , Xk ) X1 ]6 . For all n k, let Un = n
h(Xi1 , . . . , Xik ).

(k ) 1 i1 < <ik n
Then,

n(Un E[h(X1 , . . . , Xk )]) Nd (0, k 2 Σ)
n 

in distribution.
Theorem 4 obviously remains true in the context of U -estimation with convex loss. Proposition 1,
Theorems 5 and 6 require more care but also remain true in this context. Proofs are deferred to
Section D. Below, we rewrite Theorem 7 for U -estimators, where an extra multiplicative factor k
appears in the limit, accounting for the dependence of the terms in the new definition of Φn .
Theorem 10. Asymptotic distribution for U -estimators Let g E k Θ0 Rd be a measurable
selection of subgradients of ϕ. Assume the following:
(i) Φ has a unique minimizer θ in Θ, it is twice differentiable at θ and S = 2 Φ(θ ) is positive
definite;
(ii) g( , θ ) L2 (P k );
S
 1
(iii) πΘ θ
 Φ(θ ).
 has directional derivatives at S
Then,

S
 1
n(θ n θ ) k d+ πΘ θ
 Φ(θ ); Z)
 (S
n 

 1

 1

in distribution, where Z Nd (0, S BS ) and B = var(E[g(X1 , . . . , Xk , θ ) X1 ]).
Note the extra k factor in the limit in distribution.
6

Σ can also be written as E[h(X1 , X2 , . . . , Xk )h(X1 , X2 , . . . , Xk ) ] E[h(X1 , . . . , Xk )]E[h(X1 , . . . , Xk )] , that is,
the covariance of the random vectors h(X1 , X2 , . . . , Xk ) and h(X1 , X2 , . . . , Xk ), where X2 , . . . , Xk are such that
X1 , X2 , . . . , Xk , X2 , . . . , Xk are iid.

22

V.-E. BRUNEL

6. CONCLUSION AND FUTURE DIRECTIONS
We have established the asymptotic properties of constrained M -estimators with a convex loss
and a convex set of constraints, under minimal assumptions. In this work, asymptotics are only
relative to the sample size n, while the dimension d is kept fixed.
In large dimensional problems, asymptotic theory can be approached from different angles. First,
one may look at asymptotic distributions of low-dimensional projections of the M -estimator. For
instance, in the context of linear regression, [6] proves the asymptotic normality of single coordinates
of penalized M -estimators when the ratio d/n goes to some fixed, positive constant. A second angle
consists of looking at the full, joint distribution of (a rescaled version of) the M -estimator θ n , and
prove that, for some distribution Qd in Rd , some specified distance (e.g., an integral probability
metric) between the distribution of θ n and Qd goes to 0 as n, d in a certain manner. When
θ n is simply the sample mean of X1 , . . . , Xn , such an approach has been studied and called high
dimensional central limit theorems [12, 15]. However, to the best of our knowledge, such results do
not exist for other M -estimators, even with convex loss.
In the context of U -estimators, we have also let the order k of the U -process be fixed. However,
it may be relevant to also let k grow with the sample size (e.g., for median-of-means procedures).
While the asymptotics of U -statistics with increasing order have been studied only recently [14],
we leave this direction for future work on U -estimation.
